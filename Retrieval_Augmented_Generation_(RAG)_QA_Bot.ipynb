{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Necessary Libraries"
      ],
      "metadata": {
        "id": "Bigrs2hij_78"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jlUzv6xdmaY",
        "outputId": "47a62d3b-0253-4e13-df61-56a07af31c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.52.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Collecting flask-restful\n",
            "  Downloading Flask_RESTful-0.3.10-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Collecting aniso8601>=0.82 (from flask-restful)\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from flask-restful) (1.16.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from flask-restful) (2024.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.52.1-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_RESTful-0.3.10-py2.py3-none-any.whl (26 kB)\n",
            "Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aniso8601, pinecone-plugin-interface, jiter, h11, pinecone-plugin-inference, httpcore, pinecone-client, httpx, flask-restful, openai\n",
            "Successfully installed aniso8601-9.0.1 flask-restful-0.3.10 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.52.1 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install openai pinecone-client flask flask-restful"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PokDjs_seV9t",
        "outputId": "51c39a01-cfa5-46c6-be02-d1b41c0bdf90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.10/dist-packages (5.3.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2024.8.30)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Pinecone and OpenAI\n",
        "I utilized my personal API key for execution; however, I will be removing it during submission due to confidentiality concerns. Thank you for your understanding."
      ],
      "metadata": {
        "id": "lcGivYL6kTZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# Initialize OpenAI\n",
        "openai.api_key = 'OpenAI API Key goes here'\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=\"Pinecone API Key goes here\")\n",
        "index_name = \"rag-qa-bot\"\n",
        "\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=1536,\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\"\n",
        "    )\n",
        ")\n",
        "def delete_pinecone_index():\n",
        "  pc.delete_index(index_name)"
      ],
      "metadata": {
        "id": "Gid-MyGif_Xd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up RAG Functionality"
      ],
      "metadata": {
        "id": "KqBPWU1TlXMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_augmented_response(query):\n",
        "    # Embed the query using OpenAI embeddings\n",
        "    response = openai.embeddings.create(input=query, model=\"text-embedding-ada-002\")\n",
        "    embeddings = response['data'][0]['embedding']\n",
        "\n",
        "    # Retrieve relevant context from Pinecone\n",
        "    results = index.query(query_embedding, top_k=5, include_metadata=True)\n",
        "\n",
        "    # Combine the retrieved context for better response\n",
        "    context = \"\\n\".join([match['metadata']['text'] for match in results['matches']])\n",
        "\n",
        "    # Use OpenAI GPT to generate the response\n",
        "    gpt_response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=f\"Answer the question based on the following context:\\n\\nContext: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\",\n",
        "        max_tokens=150\n",
        "    )\n",
        "\n",
        "    return gpt_response['choices'][0]['text'].strip()\n"
      ],
      "metadata": {
        "id": "ZGoT0qJxe747"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Flask Server in a Thread\n",
        "The Flask server will be set up to run in a separate thread, allowing other cells to be executed while the server is running."
      ],
      "metadata": {
        "id": "JlAYBMWNlaWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_restful import Api, Resource\n",
        "import threading\n",
        "\n",
        "app = Flask(__name__)\n",
        "api = Api(app)\n",
        "\n",
        "# Define the QA endpoint\n",
        "class QABot(Resource):\n",
        "    def post(self):\n",
        "        data = request.get_json()\n",
        "        query = data.get(\"query\")\n",
        "        if query:\n",
        "            response = retrieve_augmented_response(query)\n",
        "            return jsonify({\"answer\": response})\n",
        "        return jsonify({\"error\": \"No query provided\"}), 400\n",
        "\n",
        "api.add_resource(QABot, '/qa')\n",
        "\n",
        "# Function to start Flask server in a thread\n",
        "def run_flask():\n",
        "    app.run(port=5000, threaded=True)\n",
        "\n",
        "# Start the Flask server in a thread\n",
        "flask_thread = threading.Thread(target=run_flask)\n",
        "flask_thread.start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oCeAxhLh08r",
        "outputId": "ae13fc0c-7cc0-4f8a-f1a2-5eb197141b79"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop Flask Server Functionality"
      ],
      "metadata": {
        "id": "TSLPdgHxlh_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import signal\n",
        "\n",
        "def stop_flask_server():\n",
        "    os.kill(os.getpid(), signal.SIGTERM)"
      ],
      "metadata": {
        "id": "yPBgYd5TiIc6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Curl"
      ],
      "metadata": {
        "id": "HojnFgxslpMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST http://127.0.0.1:5000/qa -H \"Content-Type: application/json\" -d '{\"query\":\"What is your business about?\"}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt7zMuNTiLuC",
        "outputId": "f70479aa-b7d2-4a8f-91be-9f85951938c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Exception on /qa [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1799, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask_restful/__init__.py\", line 489, in wrapper\n",
            "    resp = resource(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/views.py\", line 107, in view\n",
            "    return current_app.ensure_sync(self.dispatch_request)(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask_restful/__init__.py\", line 604, in dispatch_request\n",
            "    resp = meth(*args, **kwargs)\n",
            "  File \"<ipython-input-3-4b7388de4959>\", line 14, in post\n",
            "    response = retrieve_augmented_response(query)\n",
            "  File \"<ipython-input-11-2cc6389e9c95>\", line 3, in retrieve_augmented_response\n",
            "    response = openai.embeddings.create(input=query, model=\"text-embedding-ada-002\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/embeddings.py\", line 124, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1277, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 954, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1043, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1043, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1058, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Oct/2024 13:49:41] \"\u001b[35m\u001b[1mPOST /qa HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"message\": \"Internal Server Error\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temporary Workaround\n",
        "\n",
        "\n",
        "*   The error message I received, openai.RateLimitError, indicates that I have exceeded your current quota for the OpenAI API.\n",
        "*   I've temporarily modified the response function to return a static message instead of generating embeddings, but in theory, the code should work.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v0qmKMX8l7hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_augmented_response(query):\n",
        "    # Temporary static response for testing\n",
        "    return \"This is a static response for testing purposes.\""
      ],
      "metadata": {
        "id": "Ezk5iB39m4H-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Test"
      ],
      "metadata": {
        "id": "ryxahuJnm_0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST http://127.0.0.1:5000/qa -H \"Content-Type: application/json\" -d '{\"query\":\"What is your business about?\"}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrWT6F9JnFj0",
        "outputId": "4c2a5c88-9e02-4968-e0ba-3e1630d1cdd0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Oct/2024 13:49:55] \"POST /qa HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"answer\":\"This is a static response for testing purposes.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Terminating"
      ],
      "metadata": {
        "id": "PMRJ1YLrnZsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_pinecone_index()\n",
        "stop_flask_server()"
      ],
      "metadata": {
        "id": "HrbPFytOiwjN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}